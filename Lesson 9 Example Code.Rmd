---
title: "Lesson 9 Example Code"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(out.width= "70%", out.height= "70%", fig.align = "center")
```


I will be utilizing the data from the GPA vs. non-academic time data set from section 10.4 for this example code.

```{r}
library(tidyverse)

GPA = read_table2("http://www.isi-stats.com/isi/data/chap10/GPA.txt")

head(GPA)

GPA %>%
  ggplot(aes(x = hours, y = gpa)) +
  geom_point() +
  labs(x = "Non-academic time (h)", y = "GPA", title = "GPA vs. Non-Academic Time")
```
It appears as if there is a slightly negative association between these two variables. There are two unusual observations below a 2.0 GPA which are likely influential due to their large seperation from the other observations.

Let's establish our hypotheses for these tests:

$H_{0}:$ There is no association between GPA and time spent on non-academic activities.

$H_{a}:$ There is an association.

Now let's find the sample statistic we will use for our approaches. In this case, we will utilize the slope of the least squares regression line as our statistic. First a brief exploration of the **lm()** function in *R*. You will use **lm()** a lot in this course, you will learn to love it, and you will miss it when you leave the course. Like a lot of functions in *R*, it automates a lot of your work and provides more information than you know what to do with. Let's start by building a **l**inear **m**odel for our research question.
```{r}
model = lm(GPA$gpa ~ GPA$hours)

summary(model)

sample_stat = model$coefficients[[2]]
```
Starting with the first line, you should read these arguments inside the **lm()** function as "GPA as a function of hours." Using this trick will help you decipher what model you are building when you move into more complicated models.  Once we build this model we save it to the variable *model* for later use. The first use is to look at the summary of the model using the function... **summary()**. This summary provides a lot of important information about our model, much of which we will explore later. The first thing I want to do, however, is to simply establish how to write our the model from this summary output:

$\hat{y} = -0.005884 x_{1} + 3.597691$

where $x_{1}$ is non-academic time

You will recall that when we put a "hat" ( $\hat{}$ ) on something we are signifying it is an estimate. Therefore we can use this equation to find our estimate of *y* (GPA). This estimate will usually be different than the "actual" *y* values (the values in our data set). We can now identify our slope parameter ($\beta_{1}$) as -0.005884 and we will use this in the rest of the document. We can also see our intercept estimate ($\beta_{0}$) is 3.567691.

The last thing I want to point out on this summary output right now are the two r-squared values: *Multiple R-squared* and *Adjusted R-Squared*. For the purposes of this class (and your project) you will use multiple R-squared as it is the "normal" coefficient of determination discussed in your book. The adjusted R-squared is useful in predictive modeling contexts where you would like to "penalize" a model for overcomplication. If I'm trying to predict the GPA of a student and one model has three explanatory variables and an $R^{2}$ of 0.71 and another model has 10 explanatory variables and an $R^{2}$ of 0.72, I would prefer to use the less complicated model... even if accounts for less of the variation in the response variable. You would (usually) find that the adjusted R-squared would be lower for this more complicated second model given there is not much of a difference between the multiple r-squared values.

Now that we have identified our sample statistic ($B_{1}$) for our approaches, we will continue.

### Simulation-Based Approach

The first step in the simulation-based approach is always to build the null distribution. Once again, when we are building the null distribution we are assuming the truth of the null hypothesis. If there is no association between time and GPA than it doesn't matter which time is associated with GPA. We can build our null distribution of simulated slopes by shuffling our explanatory and response pairs. 

```{r}

replications_dataframe = NULL

num_reps = 1000

for (i in 1:num_reps){
  
  #Produce a new dataframe (scrambled_GPA) with a new column
  #that contains scrambled GPAs by sampling the original w/o
  #replacement.
  scrambled_GPA = GPA %>%
    mutate(new_GPA = sample(gpa, size = n(), replace = FALSE))
  
  #Produce model with this new_GPA but just pull out the slope
  trial_slope = lm(scrambled_GPA$new_GPA ~ scrambled_GPA$hours)$coefficients[[2]]
  
  #Add it to my list of simulated slopes
  replications_dataframe = rbind(replications_dataframe, data.frame(trial_slope))
  
}

replications_dataframe %>%
  ggplot(aes(x = trial_slope)) +
  geom_histogram() +
  labs(x = "Simulated Slopes", y = "Count", 
       title = "Distribution of Simulated Slopes") +
  geom_vline(xintercept = -sample_stat, color = "red") +
  geom_vline(xintercept = sample_stat, color = "red")
  
replications_dataframe %>%
  summarise(pvalue = sum(abs(trial_slope) >= abs(sample_stat)) / n())

```

I know that was a big block of code but hopefully you recognize most of it from the previous simulation-based approach example code documents. It's important to understand that this null distribution represents the distribution of slopes we would expect to see if there was no association between non-academic time and GPA. This should help demonstrate that the slope isn't always zero between non-associated variables and (perhaps more importantly) that a slope that is determined from a sample (like the statistics we've discussed previously in this class) is not the definitive ground truth about the relationship between an explanatory and response variable. I believe that previous experience with linear regression makes it harder for students to accept this compared to the other sample statistics we discuss in this course. Your sample slope applies to that sample and may or may not apply beyond the sample... hence the need for inference.

## Theory-Based Approach
First we need to verify that we meet our valitidy conditions. Check out my document on these validity conditions on the MA256 GitHub for more information.

**L**inearity and **E**qual Variance:
```{r}
model %>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  labs(x = "Fitted", y = "Residuals vs. Fitted",
       title = "Residuals vs. Fitted") +
  geom_hline(yintercept = 0)
```
There does not appear to be a pattern to the residuals and there appears to be roughly equal spacing across the domain of the fitted values.

**I**ndependence:

It is reasonable to assume that the observations in our data set are independent from each other as the amount of time that one student spends on non-academic time and their GPA is logically independent from another.

**N**ormally-distributed Residuals:
```{r}
mean_resid = mean(model$residuals)
sd_resid = sd(model$residuals)

model %>%
  ggplot(aes(x = .resid)) +
  geom_histogram() +
  labs(x = "Residuals", y = "Count",
       title = "Distribution of Residuals") +
  geom_vline(xintercept = mean_resid + 2 * sd_resid, color = "red") +
  geom_vline(xintercept = mean_resid - 2 * sd_resid, color = "red")
```
While there are appear to be two outlying residuals (something we would have expected based on our data exploration) the vast majority of the residual values falls within two standard deviations of the mean. Furthermore, the histogram appears to be uni-model with the mode located in the center of the distribution.

With these validity conditions satisfied, we can continue with our theory-based approach.

Another thing that it is easy to lose track of in the course is what exactly is the *theory-based approach* for linear regression. Students often identify **lm()** as the theory-based approach because it conducts the theory-based test behind the scenes. As you may have identified, the theory-based approach for linear regression is another t-test. The code below goes a bit more in-depth than necessary for our purpose in this class but I didn't simply want to pull values from our model summary output.

```{r}
#Sum of squared error
estimate = model$fitted.values
observed = GPA$gpa

sse = sum((observed - estimate)^2)

#Sum of squares
average_hours = mean(GPA$hours)

ss = sum((GPA$hours - average_hours)^2)

sample_size = nrow(GPA)

#Standard Error of Slope
standard_error = sqrt( ((1 / (sample_size - 2)) * sse) / ss)

tstat = (sample_stat - 0) /  standard_error

tstat
```
That was a lot of work to get a test statistic that matched what was already in the table but I wanted to demonstrate where the value comes from. Now that we have the t-statistic for our slope, we can use **pt()** to obtain our p-value. Keep in mind we are interested in the existence of an *association* between the explanatory and reponse variables which implies a two-sided test because it doesn't matter the direction of that association.

```{r}
2 * (1 - pt(abs(tstat), df = sample_size - 2))
```
Once again, we can see that this p-value is already present in our model's summary output. You will notice that the degree of freedom parameter is *n*-2 this time instead of *n*-1. This is because we lose a degree of freedom for each predictor in our model. Read more about degrees of freedom here: https://statisticsbyjim.com/hypothesis-testing/degrees-freedom-statistics/

For the purposes of our class, you don't need to go through calculating your p-value by hand, trusting the summary output is enough. However, being able to identify the actual theory-based test and understanding the process is very important to linear regression and further concepts in the course.